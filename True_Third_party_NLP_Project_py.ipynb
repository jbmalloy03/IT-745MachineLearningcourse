{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPunHQ+ML+uwZaNMDiT/ZZY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbmalloy03/IT-745_Machine_Learning_course/blob/main/True_Third_party_NLP_Project_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "232cc67c",
        "outputId": "16992a26-799b-4ac3-9791-98c9db38fad1"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import docx\n",
        "import PyPDF2\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "# =========================================================\n",
        "# Azure OpenAI Configuration\n",
        "# =========================================================\n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
        "    api_version=\"2024-02-01\",\n",
        "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        ")\n",
        "DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
        "\n",
        "# =========================================================\n",
        "# Questionnaire Configuration\n",
        "# =========================================================\n",
        "questions = {\n",
        "    \"q1\": {\"text\": \"Does the vendor have a formal cybersecurity policy?\", \"weight\": 10},\n",
        "    \"q2\": {\"text\": \"Is data encrypted in transit and at rest?\", \"weight\": 10},\n",
        "    \"q3\": {\"text\": \"Does the vendor perform regular vulnerability assessments?\", \"weight\": 10},\n",
        "    \"q4\": {\"text\": \"Is multi-factor authentication (MFA) implemented?\", \"weight\": 8},\n",
        "    \"q5\": {\"text\": \"Does the vendor comply with relevant regulations (e.g., GDPR, HIPAA)?\", \"weight\": 10},\n",
        "    \"q6\": {\"text\": \"Does the vendor store or process sensitive data?\", \"weight\": 7},\n",
        "    \"q7\": {\"text\": \"Does the vendor subcontract any critical services?\", \"weight\": 8},\n",
        "    \"q8\": {\"text\": \"Is the vendorâ€™s incident response plan tested annually?\", \"weight\": 10},\n",
        "    \"q9\": {\"text\": \"Has the vendor experienced any recent data breaches?\", \"weight\": 12},\n",
        "    \"q10\": {\"text\": \"Does the vendor provide employee cybersecurity training?\", \"weight\": 5}\n",
        "}\n",
        "\n",
        "# =========================================================\n",
        "# Control Corpus (Baseline for NLP)\n",
        "# =========================================================\n",
        "CONTROL_CORPUS = [\n",
        "    \"access control policy least privilege authentication authorization\",\n",
        "    \"incident response detection containment eradication recovery testing\",\n",
        "    \"data protection encryption classification retention privacy\",\n",
        "    \"business continuity disaster recovery testing resilience\",\n",
        "    \"vendor risk governance oversight compliance monitoring\"\n",
        "]\n",
        "\n",
        "# =========================================================\n",
        "# Helper Functions\n",
        "# =========================================================\n",
        "def extract_policy_text(uploaded_file):\n",
        "    text = \"\"\n",
        "    if uploaded_file.type == \"application/pdf\":\n",
        "        reader = PyPDF2.PdfReader(uploaded_file)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() or \"\"\n",
        "    elif uploaded_file.type == (\n",
        "        \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n",
        "    ):\n",
        "        doc = docx.Document(uploaded_file)\n",
        "        for para in doc.paragraphs:\n",
        "            text += para.text + \" \"\n",
        "    return text.lower()\n",
        "\n",
        "\n",
        "def calculate_similarity(policy_text):\n",
        "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "    tfidf = vectorizer.fit_transform([policy_text] + CONTROL_CORPUS)\n",
        "    scores = cosine_similarity(tfidf[0:1], tfidf[1:])\n",
        "    return float(np.mean(scores))\n",
        "\n",
        "\n",
        "def calculate_risk_score(responses, criticality):\n",
        "    total_weight = sum(q[\"weight\"] for q in questions.values())\n",
        "    weighted_score = 0\n",
        "\n",
        "    for key, response in responses.items():\n",
        "        weight = questions[key][\"weight\"]\n",
        "        if response == \"Yes\":\n",
        "            weighted_score += weight\n",
        "        elif response == \"Partial\":\n",
        "            weighted_score += weight * 0.5\n",
        "\n",
        "    score = (weighted_score / total_weight) * 100\n",
        "\n",
        "    if criticality == \"High\":\n",
        "        score *= 0.9\n",
        "    elif criticality == \"Low\":\n",
        "        score *= 1.1\n",
        "\n",
        "    return min(100, max(0, score))\n",
        "\n",
        "\n",
        "def classify_risk(score):\n",
        "    if score < 50:\n",
        "        return \"High Risk\"\n",
        "    elif score < 75:\n",
        "        return \"Medium Risk\"\n",
        "    else:\n",
        "        return \"Low Risk\"\n",
        "\n",
        "\n",
        "def generate_recommendations(responses, risk_class):\n",
        "    recs = []\n",
        "\n",
        "    if risk_class == \"High Risk\":\n",
        "        recs.extend([\n",
        "            \"Conduct an immediate security review and request remediation evidence.\",\n",
        "            \"Perform an audit focusing on encryption, access control, and incident response.\",\n",
        "            \"Require formal SLAs for breach notification and monitoring.\"\n",
        "        ])\n",
        "    elif risk_class == \"Medium Risk\":\n",
        "        recs.extend([\n",
        "            \"Request updated compliance reports (SOC 2, ISO 27001).\",\n",
        "            \"Increase MFA coverage and incident response testing.\"\n",
        "        ])\n",
        "    else:\n",
        "        recs.extend([\n",
        "            \"Maintain annual assessments and continuous monitoring.\",\n",
        "            \"Sustain communication with vendor security leadership.\"\n",
        "        ])\n",
        "\n",
        "    if responses.get(\"q9\") == \"Yes\":\n",
        "        recs.append(\"Recent breach identified â€” verify corrective actions.\")\n",
        "    if responses.get(\"q7\") == \"Yes\":\n",
        "        recs.append(\"Subcontractors used â€” ensure downstream security equivalence.\")\n",
        "    if responses.get(\"q10\") == \"No\":\n",
        "        recs.append(\"Employee training gap â€” mandate annual cybersecurity training.\")\n",
        "\n",
        "    return recs\n",
        "\n",
        "\n",
        "def llm_policy_analysis(policy_text, similarity_score):\n",
        "    system_prompt = (\n",
        "        \"You are a cybersecurity risk analyst. \"\n",
        "        \"Provide descriptive analysis only. \"\n",
        "        \"Do not assign risk levels or make decisions.\"\n",
        "    )\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "NLP similarity score (0â€“1): {similarity_score:.2f}\n",
        "\n",
        "Analyze the vendor policy and provide:\n",
        "1. Observed strengths\n",
        "2. Identified gaps\n",
        "3. Suggested improvements\n",
        "\n",
        "Policy text:\n",
        "{policy_text[:6000]}\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=DEPLOYMENT_NAME,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        max_tokens=400\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# =========================================================\n",
        "# Streamlit UI\n",
        "# =========================================================\n",
        "st.set_page_config(\n",
        "    page_title=\"AI-Driven Third-Party Risk Assessment\",\n",
        "    layout=\"centered\"\n",
        ")\n",
        "\n",
        "st.title(\"ðŸ§  AI-Driven Third-Party Risk Assessment Dashboard\")\n",
        "st.write(\"Assess vendor cybersecurity readiness using questionnaires, NLP, and AI-assisted analysis.\")\n",
        "\n",
        "# Vendor Information\n",
        "st.header(\"Vendor Information\")\n",
        "vendor = st.text_input(\"Vendor Name\", \"SampleVendorCo\")\n",
        "industry = st.text_input(\"Vendor Industry\", \"Finance\")\n",
        "criticality = st.selectbox(\"Vendor Criticality\", [\"High\", \"Medium\", \"Low\"])\n",
        "\n",
        "# Questionnaire\n",
        "st.header(\"Risk Assessment Questionnaire\")\n",
        "responses = {}\n",
        "for key, q in questions.items():\n",
        "    responses[key] = st.radio(q[\"text\"], [\"Yes\", \"No\", \"Partial\"], horizontal=True)\n",
        "\n",
        "# Policy Upload\n",
        "st.header(\"Upload Vendor Policy Documentation\")\n",
        "uploaded_file = st.file_uploader(\"Upload PDF or DOCX\", type=[\"pdf\", \"docx\"])\n",
        "\n",
        "# Run Assessment\n",
        "if st.button(\"Run AI-Driven Assessment\"):\n",
        "\n",
        "    score = calculate_risk_score(responses, criticality)\n",
        "    risk_class = classify_risk(score)\n",
        "    recommendations = generate_recommendations(responses, risk_class)\n",
        "    timestamp = datetime.utcnow().isoformat() + \"Z\"\n",
        "\n",
        "    similarity_score = None\n",
        "    llm_output = None\n",
        "\n",
        "    if uploaded_file:\n",
        "        policy_text = extract_policy_text(uploaded_file)\n",
        "        similarity_score = calculate_similarity(policy_text)\n",
        "\n",
        "        with st.spinner(\"Running Azure OpenAI analysis...\"):\n",
        "            llm_output = llm_policy_analysis(policy_text, similarity_score)\n",
        "\n",
        "    # Results\n",
        "    st.subheader(\"Assessment Results\")\n",
        "    st.metric(\"Risk Score\", f\"{round(score,1)} / 100\")\n",
        "    st.metric(\"Risk Classification\", risk_class)\n",
        "    st.progress(int(score))\n",
        "\n",
        "    if similarity_score is not None:\n",
        "        st.metric(\"NLP Similarity Score\", f\"{similarity_score:.2f}\")\n",
        "\n",
        "    st.write(\"### ðŸ§© AI-Generated Recommendations\")\n",
        "    for r in recommendations:\n",
        "        st.markdown(f\"- {r}\")\n",
        "\n",
        "    if llm_output:\n",
        "        st.write(\"### ðŸ¤– LLM-Assisted Policy Analysis\")\n",
        "        st.write(llm_output)\n",
        "\n",
        "    # Export\n",
        "    result = {\n",
        "        \"vendor\": vendor,\n",
        "        \"industry\": industry,\n",
        "        \"criticality\": criticality,\n",
        "        \"risk_score\": round(score, 1),\n",
        "        \"risk_classification\": risk_class,\n",
        "        \"nlp_similarity_score\": similarity_score,\n",
        "        \"recommendations\": recommendations,\n",
        "        \"llm_analysis\": llm_output,\n",
        "        \"responses\": responses,\n",
        "        \"timestamp\": timestamp\n",
        "    }\n",
        "\n",
        "    st.download_button(\n",
        "        \"Download JSON Report\",\n",
        "        json.dumps(result, indent=4),\n",
        "        f\"AI_TPRM_Report_{vendor}.json\",\n",
        "        \"application/json\"\n",
        "    )\n",
        "\n",
        "    df = pd.DataFrame([result])\n",
        "    st.download_button(\n",
        "        \"Download CSV Summary\",\n",
        "        df.to_csv(index=False),\n",
        "        f\"AI_TPRM_Report_{vendor}.csv\",\n",
        "        \"text/csv\"\n",
        "    )\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.caption(\"AI-Driven Cybersecurity Research on Third-Party Risk Management Â© 2026\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    }
  ]
}